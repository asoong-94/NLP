Noah A. Smith
2/21/08

David Bamman
2/14/14

This package includes scripts for training (train_hmm.pl or train_hmm.py -- both are equivalent), running (viterbi.pl), and evaluating (tag_acc.pl) HMMs for sequence tagging.  Each script is documented on its own.  Here's a toy example to check that things work.

Train a bigram HMM tagger from sections 2-21 of the Penn Treebank:

  # Perl:
  ./train_hmm.pl ptb.2-21.tgs ptb.2-21.txt > my.hmm

  # Python:
  ./train_hmm.py ptb.2-21.tgs ptb.2-21.txt > my.hmm

Run the Viterbi algorithm to tag some data:

  ./viterbi.pl my.hmm < ptb.22.txt > my.out

Evaluate:

  ./tag_acc.pl ptb.22.tgs my.out

Output should be as follows, modulo floating point differences:

error rate by word:      0.0540917815389984 (2170 errors out of 40117)
error rate by sentence:  0.655882352941176 (1115 errors out of 1700)
